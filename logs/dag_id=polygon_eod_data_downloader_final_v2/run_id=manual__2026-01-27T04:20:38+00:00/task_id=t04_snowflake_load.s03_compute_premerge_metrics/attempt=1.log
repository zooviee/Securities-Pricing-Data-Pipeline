{"timestamp":"2026-01-27T04:21:16.953806Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-27T04:21:16.954014Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/get_securities_data.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T04:21:17.033818Z","level":"warning","event":"Skipping masking for a secret as it's too short (<5 chars)","logger":"airflow._shared.secrets_masker.secrets_masker","filename":"secrets_masker.py","lineno":557}
{"timestamp":"2026-01-27T04:21:17.049738Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:21:17.050226Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:21:17.050280Z","level":"info","event":"Current task name:t04_snowflake_load.s03_compute_premerge_metrics","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:21:17.050315Z","level":"info","event":"Dag name:polygon_eod_data_downloader_final_v2","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:21:17.047902Z","level":"info","event":"Executing: ------------------------------------------------------------\n-- PURPOSE:\n-- Estimate insert vs update counts when loading RAW → CORE for a specific trading date (passed from Airflow).\n-- This is a pre-merge audit step to validate data volume, ensure consistency, and prevent duplicate loads.\n------------------------------------------------------------\n\n\n-- Set the active compute and database context\nUSE WAREHOUSE WH_INGEST;    -- small warehouse for ingestion/ETL\nUSE DATABASE SEC_PRICING;   -- working within securities pricing database\n\n\n------------------------------------------------------------\n-- Compute record statistics for the target trading date\n------------------------------------------------------------\nWITH td AS (\n  -- Pull trading date dynamically from Airflow XCom context\n  SELECT TO_DATE('2026-01-23') AS d\n),\nraw_cnt AS (\n  -- Count all records in RAW for that trading date\n  SELECT COUNT(*) AS c\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\ntoday_keys AS (\n  -- Extract distinct SYMBOL + TRADE_DATE keys for the trading day\n  -- Normalize symbol casing and trim spaces to avoid false mismatches\n  SELECT DISTINCT UPPER(TRIM(SYMBOL)) AS SYMBOL, TRADE_DATE\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\nkey_cnt AS (\n  -- Total unique keys (distinct securities traded that day)\n  SELECT COUNT(*) AS c FROM today_keys\n),\ncore_existing AS (\n  -- Identify how many of today's keys already exist in CORE\n  -- This represents potential *updates* during the MERGE.\n  SELECT COUNT(*) AS c\n  FROM today_keys k\n  JOIN CORE.EOD_PRICES t\n    ON UPPER(TRIM(t.SYMBOL)) = k.SYMBOL AND t.TRADE_DATE = k.TRADE_DATE\n)\nSELECT\n  r.c                         AS raw_cnt,            -- total rows in RAW\n  e.c                         AS core_existing_cnt,  -- keys already in CORE\n  (k.c - e.c)                 AS core_inserts_est,   -- new rows expected\n  e.c                         AS core_updates_est    -- updates expected\nFROM raw_cnt r\nCROSS JOIN key_cnt k\nCROSS JOIN core_existing e;","logger":"airflow.task.operators.airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator","filename":"sql.py","lineno":394}
{"timestamp":"2026-01-27T04:21:17.053463Z","level":"info","event":"Snowflake Connector for Python Version: 4.0.0, Python Version: 3.12.12, Platform: Linux-6.12.54-linuxkit-aarch64-with-glibc2.36","logger":"snowflake.connector.connection","filename":"connection.py","lineno":586}
{"timestamp":"2026-01-27T04:21:17.053718Z","level":"info","event":"Connecting to GLOBAL Snowflake domain","logger":"snowflake.connector.connection","filename":"connection.py","lineno":1629}
{"timestamp":"2026-01-27T04:21:18.529622Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- PURPOSE:\n-- Estimate insert vs update counts when loading RAW → CORE for a specific trading date (passed from Airflow).\n-- This is a pre-merge audit step to validate data volume, ensure consistency, and prevent duplicate loads.\n------------------------------------------------------------\n\n\n-- Set the active compute and database context\nUSE WAREHOUSE WH_INGEST;    -- small warehouse for ingestion/ETL, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":592}
{"timestamp":"2026-01-27T04:21:18.530001Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- PURPOSE:\n-- Estimate insert vs update counts when loading RAW → CORE for a specific trading date (passed from Airflow).\n-- This is a pre-merge audit step to validate data volume, ensure consistency, and prevent duplicate loads.\n------------------------------------------------------------\n\n\n-- Set the active compute and database context\nUSE WAREHOUSE WH_INGEST;    -- small warehouse for ingestion/ETL, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":802}
{"timestamp":"2026-01-27T04:21:18.613444Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":814}
{"timestamp":"2026-01-27T04:21:18.613998Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":605}
{"timestamp":"2026-01-27T04:21:18.614054Z","level":"info","event":"Snowflake query id: 01c20105-3203-ae81-0007-131a0002102a","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":606}
{"timestamp":"2026-01-27T04:21:18.614091Z","level":"info","event":"Running statement: USE DATABASE SEC_PRICING;   -- working within securities pricing database, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":592}
{"timestamp":"2026-01-27T04:21:18.614163Z","level":"info","event":"Running statement: USE DATABASE SEC_PRICING;   -- working within securities pricing database, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":802}
{"timestamp":"2026-01-27T04:21:18.703270Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":814}
{"timestamp":"2026-01-27T04:21:18.703628Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":605}
{"timestamp":"2026-01-27T04:21:18.703699Z","level":"info","event":"Snowflake query id: 01c20105-3203-ae0e-0007-131a00020066","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":606}
{"timestamp":"2026-01-27T04:21:18.703750Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- Compute record statistics for the target trading date\n------------------------------------------------------------\nWITH td AS (\n  -- Pull trading date dynamically from Airflow XCom context\n  SELECT TO_DATE('2026-01-23') AS d\n),\nraw_cnt AS (\n  -- Count all records in RAW for that trading date\n  SELECT COUNT(*) AS c\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\ntoday_keys AS (\n  -- Extract distinct SYMBOL + TRADE_DATE keys for the trading day\n  -- Normalize symbol casing and trim spaces to avoid false mismatches\n  SELECT DISTINCT UPPER(TRIM(SYMBOL)) AS SYMBOL, TRADE_DATE\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\nkey_cnt AS (\n  -- Total unique keys (distinct securities traded that day)\n  SELECT COUNT(*) AS c FROM today_keys\n),\ncore_existing AS (\n  -- Identify how many of today's keys already exist in CORE\n  -- This represents potential *updates* during the MERGE.\n  SELECT COUNT(*) AS c\n  FROM today_keys k\n  JOIN CORE.EOD_PRICES t\n    ON UPPER(TRIM(t.SYMBOL)) = k.SYMBOL AND t.TRADE_DATE = k.TRADE_DATE\n)\nSELECT\n  r.c                         AS raw_cnt,            -- total rows in RAW\n  e.c                         AS core_existing_cnt,  -- keys already in CORE\n  (k.c - e.c)                 AS core_inserts_est,   -- new rows expected\n  e.c                         AS core_updates_est    -- updates expected\nFROM raw_cnt r\nCROSS JOIN key_cnt k\nCROSS JOIN core_existing e;, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":592}
{"timestamp":"2026-01-27T04:21:18.703801Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- Compute record statistics for the target trading date\n------------------------------------------------------------\nWITH td AS (\n  -- Pull trading date dynamically from Airflow XCom context\n  SELECT TO_DATE('2026-01-23') AS d\n),\nraw_cnt AS (\n  -- Count all records in RAW for that trading date\n  SELECT COUNT(*) AS c\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\ntoday_keys AS (\n  -- Extract distinct SYMBOL + TRADE_DATE keys for the trading day\n  -- Normalize symbol casing and trim spaces to avoid false mismatches\n  SELECT DISTINCT UPPER(TRIM(SYMBOL)) AS SYMBOL, TRADE_DATE\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\nkey_cnt AS (\n  -- Total unique keys (distinct securities traded that day)\n  SELECT COUNT(*) AS c FROM today_keys\n),\ncore_existing AS (\n  -- Identify how many of today's keys already exist in CORE\n  -- This represents potential *updates* during the MERGE.\n  SELECT COUNT(*) AS c\n  FROM today_keys k\n  JOIN CORE.EOD_PRICES t\n    ON UPPER(TRIM(t.SYMBOL)) = k.SYMBOL AND t.TRADE_DATE = k.TRADE_DATE\n)\nSELECT\n  r.c                         AS raw_cnt,            -- total rows in RAW\n  e.c                         AS core_existing_cnt,  -- keys already in CORE\n  (k.c - e.c)                 AS core_inserts_est,   -- new rows expected\n  e.c                         AS core_updates_est    -- updates expected\nFROM raw_cnt r\nCROSS JOIN key_cnt k\nCROSS JOIN core_existing e;, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":802}
{"timestamp":"2026-01-27T04:21:19.334830Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":814}
{"timestamp":"2026-01-27T04:21:19.336340Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":605}
{"timestamp":"2026-01-27T04:21:19.336491Z","level":"info","event":"Snowflake query id: 01c20105-3203-ad7c-0007-131a00022036","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":606}
{"timestamp":"2026-01-27T04:21:19.491966Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019bfdae-fbf6-76d4-9a9f-6638ea52cce9'), task_id='t04_snowflake_load.s03_compute_premerge_metrics', dag_id='polygon_eod_data_downloader_final_v2', run_id='manual__2026-01-27T04:20:38+00:00', try_number=1, dag_version_id=UUID('019bfdad-fa5a-7a74-bd44-ef4c0788f661'), map_index=-1, hostname='fb127cf7fdfa', context_carrier={}, task=<Task(SQLExecuteQueryOperator): t04_snowflake_load.s03_compute_premerge_metrics>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=3, start_date=datetime.datetime(2026, 1, 27, 4, 21, 16, 842343, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1450}
{"timestamp":"2026-01-27T04:21:19.522149Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:21:19.524142Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:21:19.524259Z","level":"info","event":"Task operator:<Task(SQLExecuteQueryOperator): t04_snowflake_load.s03_compute_premerge_metrics>","logger":"task.stdout"}
