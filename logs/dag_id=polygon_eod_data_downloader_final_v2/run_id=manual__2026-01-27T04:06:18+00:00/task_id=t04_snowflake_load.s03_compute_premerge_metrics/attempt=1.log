{"timestamp":"2026-01-27T04:06:26.513885Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-27T04:06:26.514240Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/get_securities_data.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T04:06:26.647987Z","level":"warning","event":"Skipping masking for a secret as it's too short (<5 chars)","logger":"airflow._shared.secrets_masker.secrets_masker","filename":"secrets_masker.py","lineno":557}
{"timestamp":"2026-01-27T04:06:26.712509Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:06:26.712699Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:06:26.713174Z","level":"info","event":"Current task name:t04_snowflake_load.s03_compute_premerge_metrics","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:06:26.713266Z","level":"info","event":"Dag name:polygon_eod_data_downloader_final_v2","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:06:26.713337Z","level":"info","event":"Executing: ------------------------------------------------------------\n-- PURPOSE:\n-- Estimate insert vs update counts when loading RAW → CORE for a specific trading date (passed from Airflow).\n-- This is a pre-merge audit step to validate data volume, ensure consistency, and prevent duplicate loads.\n------------------------------------------------------------\n\n\n-- Set the active compute and database context\nUSE WAREHOUSE WH_INGEST;    -- small warehouse for ingestion/ETL\nUSE DATABASE SEC_PRICING;   -- working within securities pricing database\n\n\n------------------------------------------------------------\n-- Compute record statistics for the target trading date\n------------------------------------------------------------\nWITH td AS (\n  -- Pull trading date dynamically from Airflow XCom context\n  SELECT TO_DATE('2026-01-23') AS d\n),\nraw_cnt AS (\n  -- Count all records in RAW for that trading date\n  SELECT COUNT(*) AS c\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\ntoday_keys AS (\n  -- Extract distinct SYMBOL + TRADE_DATE keys for the trading day\n  -- Normalize symbol casing and trim spaces to avoid false mismatches\n  SELECT DISTINCT UPPER(TRIM(SYMBOL)) AS SYMBOL, TRADE_DATE\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\nkey_cnt AS (\n  -- Total unique keys (distinct securities traded that day)\n  SELECT COUNT(*) AS c FROM today_keys\n),\ncore_existing AS (\n  -- Identify how many of today's keys already exist in CORE\n  -- This represents potential *updates* during the MERGE.\n  SELECT COUNT(*) AS c\n  FROM today_keys k\n  JOIN CORE.EOD_PRICES t\n    ON UPPER(TRIM(t.SYMBOL)) = k.SYMBOL AND t.TRADE_DATE = k.TRADE_DATE\n)\nSELECT\n  r.c                         AS raw_cnt,            -- total rows in RAW\n  e.c                         AS core_existing_cnt,  -- keys already in CORE\n  (k.c - e.c)                 AS core_inserts_est,   -- new rows expected\n  e.c                         AS core_updates_est    -- updates expected\nFROM raw_cnt r\nCROSS JOIN key_cnt k\nCROSS JOIN core_existing e;","logger":"airflow.task.operators.airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator","filename":"sql.py","lineno":394}
{"timestamp":"2026-01-27T04:06:26.728240Z","level":"info","event":"Snowflake Connector for Python Version: 4.0.0, Python Version: 3.12.12, Platform: Linux-6.12.54-linuxkit-aarch64-with-glibc2.36","logger":"snowflake.connector.connection","filename":"connection.py","lineno":586}
{"timestamp":"2026-01-27T04:06:26.728737Z","level":"info","event":"Connecting to GLOBAL Snowflake domain","logger":"snowflake.connector.connection","filename":"connection.py","lineno":1629}
{"timestamp":"2026-01-27T04:06:29.311762Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- PURPOSE:\n-- Estimate insert vs update counts when loading RAW → CORE for a specific trading date (passed from Airflow).\n-- This is a pre-merge audit step to validate data volume, ensure consistency, and prevent duplicate loads.\n------------------------------------------------------------\n\n\n-- Set the active compute and database context\nUSE WAREHOUSE WH_INGEST;    -- small warehouse for ingestion/ETL, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":592}
{"timestamp":"2026-01-27T04:06:29.311895Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- PURPOSE:\n-- Estimate insert vs update counts when loading RAW → CORE for a specific trading date (passed from Airflow).\n-- This is a pre-merge audit step to validate data volume, ensure consistency, and prevent duplicate loads.\n------------------------------------------------------------\n\n\n-- Set the active compute and database context\nUSE WAREHOUSE WH_INGEST;    -- small warehouse for ingestion/ETL, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":802}
{"timestamp":"2026-01-27T04:06:29.385667Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":814}
{"timestamp":"2026-01-27T04:06:29.385845Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":605}
{"timestamp":"2026-01-27T04:06:29.385885Z","level":"info","event":"Snowflake query id: 01c200f6-3203-ad64-0007-131a0002301a","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":606}
{"timestamp":"2026-01-27T04:06:29.385911Z","level":"info","event":"Running statement: USE DATABASE SEC_PRICING;   -- working within securities pricing database, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":592}
{"timestamp":"2026-01-27T04:06:29.385930Z","level":"info","event":"Running statement: USE DATABASE SEC_PRICING;   -- working within securities pricing database, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":802}
{"timestamp":"2026-01-27T04:06:29.470879Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":814}
{"timestamp":"2026-01-27T04:06:29.471021Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":605}
{"timestamp":"2026-01-27T04:06:29.471060Z","level":"info","event":"Snowflake query id: 01c200f6-3203-ae81-0007-131a00021016","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":606}
{"timestamp":"2026-01-27T04:06:29.471086Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- Compute record statistics for the target trading date\n------------------------------------------------------------\nWITH td AS (\n  -- Pull trading date dynamically from Airflow XCom context\n  SELECT TO_DATE('2026-01-23') AS d\n),\nraw_cnt AS (\n  -- Count all records in RAW for that trading date\n  SELECT COUNT(*) AS c\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\ntoday_keys AS (\n  -- Extract distinct SYMBOL + TRADE_DATE keys for the trading day\n  -- Normalize symbol casing and trim spaces to avoid false mismatches\n  SELECT DISTINCT UPPER(TRIM(SYMBOL)) AS SYMBOL, TRADE_DATE\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\nkey_cnt AS (\n  -- Total unique keys (distinct securities traded that day)\n  SELECT COUNT(*) AS c FROM today_keys\n),\ncore_existing AS (\n  -- Identify how many of today's keys already exist in CORE\n  -- This represents potential *updates* during the MERGE.\n  SELECT COUNT(*) AS c\n  FROM today_keys k\n  JOIN CORE.EOD_PRICES t\n    ON UPPER(TRIM(t.SYMBOL)) = k.SYMBOL AND t.TRADE_DATE = k.TRADE_DATE\n)\nSELECT\n  r.c                         AS raw_cnt,            -- total rows in RAW\n  e.c                         AS core_existing_cnt,  -- keys already in CORE\n  (k.c - e.c)                 AS core_inserts_est,   -- new rows expected\n  e.c                         AS core_updates_est    -- updates expected\nFROM raw_cnt r\nCROSS JOIN key_cnt k\nCROSS JOIN core_existing e;, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":592}
{"timestamp":"2026-01-27T04:06:29.471111Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- Compute record statistics for the target trading date\n------------------------------------------------------------\nWITH td AS (\n  -- Pull trading date dynamically from Airflow XCom context\n  SELECT TO_DATE('2026-01-23') AS d\n),\nraw_cnt AS (\n  -- Count all records in RAW for that trading date\n  SELECT COUNT(*) AS c\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\ntoday_keys AS (\n  -- Extract distinct SYMBOL + TRADE_DATE keys for the trading day\n  -- Normalize symbol casing and trim spaces to avoid false mismatches\n  SELECT DISTINCT UPPER(TRIM(SYMBOL)) AS SYMBOL, TRADE_DATE\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\nkey_cnt AS (\n  -- Total unique keys (distinct securities traded that day)\n  SELECT COUNT(*) AS c FROM today_keys\n),\ncore_existing AS (\n  -- Identify how many of today's keys already exist in CORE\n  -- This represents potential *updates* during the MERGE.\n  SELECT COUNT(*) AS c\n  FROM today_keys k\n  JOIN CORE.EOD_PRICES t\n    ON UPPER(TRIM(t.SYMBOL)) = k.SYMBOL AND t.TRADE_DATE = k.TRADE_DATE\n)\nSELECT\n  r.c                         AS raw_cnt,            -- total rows in RAW\n  e.c                         AS core_existing_cnt,  -- keys already in CORE\n  (k.c - e.c)                 AS core_inserts_est,   -- new rows expected\n  e.c                         AS core_updates_est    -- updates expected\nFROM raw_cnt r\nCROSS JOIN key_cnt k\nCROSS JOIN core_existing e;, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":802}
{"timestamp":"2026-01-27T04:06:30.337449Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":814}
{"timestamp":"2026-01-27T04:06:30.338035Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":605}
{"timestamp":"2026-01-27T04:06:30.338077Z","level":"info","event":"Snowflake query id: 01c200f6-3203-ae0e-0007-131a0002004e","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":606}
{"timestamp":"2026-01-27T04:06:30.509462Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019bfda1-8600-73e1-9045-c6604fb8c3ec'), task_id='t04_snowflake_load.s03_compute_premerge_metrics', dag_id='polygon_eod_data_downloader_final_v2', run_id='manual__2026-01-27T04:06:18+00:00', try_number=1, dag_version_id=UUID('019bfd9a-04bb-7ea8-81ec-4a0eb0ec4872'), map_index=-1, hostname='fb127cf7fdfa', context_carrier={}, task=<Task(SQLExecuteQueryOperator): t04_snowflake_load.s03_compute_premerge_metrics>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=3, start_date=datetime.datetime(2026, 1, 27, 4, 6, 26, 323050, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1450}
{"timestamp":"2026-01-27T04:06:30.539360Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:06:30.539591Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:06:30.540404Z","level":"info","event":"Task operator:<Task(SQLExecuteQueryOperator): t04_snowflake_load.s03_compute_premerge_metrics>","logger":"task.stdout"}
