{"timestamp":"2026-01-27T04:02:32.279497Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-27T04:02:32.279795Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/get_securities_data.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T04:02:32.396131Z","level":"warning","event":"Skipping masking for a secret as it's too short (<5 chars)","logger":"airflow.sdk._shared.secrets_masker.secrets_masker","filename":"secrets_masker.py","lineno":557}
{"timestamp":"2026-01-27T04:02:32.397283Z","level":"warning","event":"Skipping masking for a secret as it's too short (<5 chars)","logger":"airflow._shared.secrets_masker.secrets_masker","filename":"secrets_masker.py","lineno":557}
{"timestamp":"2026-01-27T04:02:32.419102Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:02:32.419292Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:02:32.419471Z","level":"info","event":"Current task name:t04_snowflake_load.s03_compute_premerge_metrics","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:02:32.419543Z","level":"info","event":"Dag name:polygon_eod_data_downloader_final_v2","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:02:32.419623Z","level":"info","event":"Executing: ------------------------------------------------------------\n-- PURPOSE:\n-- Estimate insert vs update counts when loading RAW → CORE for a specific trading date (passed from Airflow).\n-- This is a pre-merge audit step to validate data volume, ensure consistency, and prevent duplicate loads.\n------------------------------------------------------------\n\n\n-- Set the active compute and database context\nUSE WAREHOUSE WH_INGEST;    -- small warehouse for ingestion/ETL\nUSE DATABASE SEC_PRICING;   -- working within securities pricing database\n\n\n------------------------------------------------------------\n-- Compute record statistics for the target trading date\n------------------------------------------------------------\nWITH td AS (\n  -- Pull trading date dynamically from Airflow XCom context\n  SELECT TO_DATE('2026-01-23') AS d\n),\nraw_cnt AS (\n  -- Count all records in RAW for that trading date\n  SELECT COUNT(*) AS c\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\ntoday_keys AS (\n  -- Extract distinct SYMBOL + TRADE_DATE keys for the trading day\n  -- Normalize symbol casing and trim spaces to avoid false mismatches\n  SELECT DISTINCT UPPER(TRIM(SYMBOL)) AS SYMBOL, TRADE_DATE\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\nkey_cnt AS (\n  -- Total unique keys (distinct securities traded that day)\n  SELECT COUNT(*) AS c FROM today_keys\n),\ncore_existing AS (\n  -- Identify how many of today's keys already exist in CORE\n  -- This represents potential *updates* during the MERGE.\n  SELECT COUNT(*) AS c\n  FROM today_keys k\n  JOIN CORE.EOD_PRICES t\n    ON UPPER(TRIM(t.SYMBOL)) = k.SYMBOL AND t.TRADE_DATE = k.TRADE_DATE\n)\nSELECT\n  r.c                         AS raw_cnt,            -- total rows in RAW\n  e.c                         AS core_existing_cnt,  -- keys already in CORE\n  (k.c - e.c)                 AS core_inserts_est,   -- new rows expected\n  e.c                         AS core_updates_est    -- updates expected\nFROM raw_cnt r\nCROSS JOIN key_cnt k\nCROSS JOIN core_existing e;","logger":"airflow.task.operators.airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator","filename":"sql.py","lineno":394}
{"timestamp":"2026-01-27T04:02:32.428572Z","level":"info","event":"Snowflake Connector for Python Version: 4.0.0, Python Version: 3.12.12, Platform: Linux-6.12.54-linuxkit-aarch64-with-glibc2.36","logger":"snowflake.connector.connection","filename":"connection.py","lineno":586}
{"timestamp":"2026-01-27T04:02:32.428832Z","level":"info","event":"Connecting to GLOBAL Snowflake domain","logger":"snowflake.connector.connection","filename":"connection.py","lineno":1629}
{"timestamp":"2026-01-27T04:02:36.526172Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- PURPOSE:\n-- Estimate insert vs update counts when loading RAW → CORE for a specific trading date (passed from Airflow).\n-- This is a pre-merge audit step to validate data volume, ensure consistency, and prevent duplicate loads.\n------------------------------------------------------------\n\n\n-- Set the active compute and database context\nUSE WAREHOUSE WH_INGEST;    -- small warehouse for ingestion/ETL, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":592}
{"timestamp":"2026-01-27T04:02:36.526472Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- PURPOSE:\n-- Estimate insert vs update counts when loading RAW → CORE for a specific trading date (passed from Airflow).\n-- This is a pre-merge audit step to validate data volume, ensure consistency, and prevent duplicate loads.\n------------------------------------------------------------\n\n\n-- Set the active compute and database context\nUSE WAREHOUSE WH_INGEST;    -- small warehouse for ingestion/ETL, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":802}
{"timestamp":"2026-01-27T04:02:37.330455Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":814}
{"timestamp":"2026-01-27T04:02:37.330722Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":605}
{"timestamp":"2026-01-27T04:02:37.330793Z","level":"info","event":"Snowflake query id: 01c200f2-3203-ad7c-0007-131a0002200e","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":606}
{"timestamp":"2026-01-27T04:02:37.330843Z","level":"info","event":"Running statement: USE DATABASE SEC_PRICING;   -- working within securities pricing database, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":592}
{"timestamp":"2026-01-27T04:02:37.330886Z","level":"info","event":"Running statement: USE DATABASE SEC_PRICING;   -- working within securities pricing database, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":802}
{"timestamp":"2026-01-27T04:02:37.460529Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":814}
{"timestamp":"2026-01-27T04:02:37.460635Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":605}
{"timestamp":"2026-01-27T04:02:37.460663Z","level":"info","event":"Snowflake query id: 01c200f2-3203-ad64-0007-131a0002300e","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":606}
{"timestamp":"2026-01-27T04:02:37.460684Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- Compute record statistics for the target trading date\n------------------------------------------------------------\nWITH td AS (\n  -- Pull trading date dynamically from Airflow XCom context\n  SELECT TO_DATE('2026-01-23') AS d\n),\nraw_cnt AS (\n  -- Count all records in RAW for that trading date\n  SELECT COUNT(*) AS c\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\ntoday_keys AS (\n  -- Extract distinct SYMBOL + TRADE_DATE keys for the trading day\n  -- Normalize symbol casing and trim spaces to avoid false mismatches\n  SELECT DISTINCT UPPER(TRIM(SYMBOL)) AS SYMBOL, TRADE_DATE\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\nkey_cnt AS (\n  -- Total unique keys (distinct securities traded that day)\n  SELECT COUNT(*) AS c FROM today_keys\n),\ncore_existing AS (\n  -- Identify how many of today's keys already exist in CORE\n  -- This represents potential *updates* during the MERGE.\n  SELECT COUNT(*) AS c\n  FROM today_keys k\n  JOIN CORE.EOD_PRICES t\n    ON UPPER(TRIM(t.SYMBOL)) = k.SYMBOL AND t.TRADE_DATE = k.TRADE_DATE\n)\nSELECT\n  r.c                         AS raw_cnt,            -- total rows in RAW\n  e.c                         AS core_existing_cnt,  -- keys already in CORE\n  (k.c - e.c)                 AS core_inserts_est,   -- new rows expected\n  e.c                         AS core_updates_est    -- updates expected\nFROM raw_cnt r\nCROSS JOIN key_cnt k\nCROSS JOIN core_existing e;, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":592}
{"timestamp":"2026-01-27T04:02:37.460700Z","level":"info","event":"Running statement: ------------------------------------------------------------\n-- Compute record statistics for the target trading date\n------------------------------------------------------------\nWITH td AS (\n  -- Pull trading date dynamically from Airflow XCom context\n  SELECT TO_DATE('2026-01-23') AS d\n),\nraw_cnt AS (\n  -- Count all records in RAW for that trading date\n  SELECT COUNT(*) AS c\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\ntoday_keys AS (\n  -- Extract distinct SYMBOL + TRADE_DATE keys for the trading day\n  -- Normalize symbol casing and trim spaces to avoid false mismatches\n  SELECT DISTINCT UPPER(TRIM(SYMBOL)) AS SYMBOL, TRADE_DATE\n  FROM RAW.RAW_EOD_PRICES\n  WHERE TRADE_DATE = (SELECT d FROM td)\n),\nkey_cnt AS (\n  -- Total unique keys (distinct securities traded that day)\n  SELECT COUNT(*) AS c FROM today_keys\n),\ncore_existing AS (\n  -- Identify how many of today's keys already exist in CORE\n  -- This represents potential *updates* during the MERGE.\n  SELECT COUNT(*) AS c\n  FROM today_keys k\n  JOIN CORE.EOD_PRICES t\n    ON UPPER(TRIM(t.SYMBOL)) = k.SYMBOL AND t.TRADE_DATE = k.TRADE_DATE\n)\nSELECT\n  r.c                         AS raw_cnt,            -- total rows in RAW\n  e.c                         AS core_existing_cnt,  -- keys already in CORE\n  (k.c - e.c)                 AS core_inserts_est,   -- new rows expected\n  e.c                         AS core_updates_est    -- updates expected\nFROM raw_cnt r\nCROSS JOIN key_cnt k\nCROSS JOIN core_existing e;, parameters: None","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":802}
{"timestamp":"2026-01-27T04:02:38.251242Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"sql.py","lineno":814}
{"timestamp":"2026-01-27T04:02:38.251590Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":605}
{"timestamp":"2026-01-27T04:02:38.251631Z","level":"info","event":"Snowflake query id: 01c200f2-3203-ae0e-0007-131a00020046","logger":"airflow.task.hooks.airflow.providers.snowflake.hooks.snowflake.SnowflakeHook","filename":"snowflake.py","lineno":606}
{"timestamp":"2026-01-27T04:02:38.404803Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019bfd9d-ee29-70b9-81ac-d875266ed4a7'), task_id='t04_snowflake_load.s03_compute_premerge_metrics', dag_id='polygon_eod_data_downloader_final_v2', run_id='manual__2026-01-27T04:02:22+00:00', try_number=1, dag_version_id=UUID('019bfd9a-04bb-7ea8-81ec-4a0eb0ec4872'), map_index=-1, hostname='fb127cf7fdfa', context_carrier={}, task=<Task(SQLExecuteQueryOperator): t04_snowflake_load.s03_compute_premerge_metrics>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=3, start_date=datetime.datetime(2026, 1, 27, 4, 2, 32, 130391, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1450}
{"timestamp":"2026-01-27T04:02:38.425652Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:02:38.425810Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2026-01-27T04:02:38.426168Z","level":"info","event":"Task operator:<Task(SQLExecuteQueryOperator): t04_snowflake_load.s03_compute_premerge_metrics>","logger":"task.stdout"}
